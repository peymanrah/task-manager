# SEVAL Scraping Raw Data Pipeline ‚Äî Spec

## Overview
Analyze and process the SEVAL (Search Evaluation) scraping raw data output. This dataset compares AI assistant responses (Copilot, ChatGPT, Gemini) across multiple query sets and snapshots.

## Data Inventory
| File | Description |
|------|-------------|
| `QuerySet.tsv` | Master query definitions with IDs and categories |
| `Snapshot.yaml` | Snapshot configuration and metadata |
| `evaluation_consolidated.csv` | Side-by-side comparison of Copilot/ChatGPT/Gemini responses |
| `conversations_copilot.tsv` | Raw Copilot conversation logs |
| `conversations_chatgpt.tsv` | Raw ChatGPT conversation logs |
| `conversations_gemini.tsv` | Raw Gemini conversation logs |
| `*.py` scripts | 20+ Python scripts for scraping, parsing, and analysis |

## Subtasks
- [x] Explore folder structure and catalog files
- [ ] Parse and validate QuerySet.tsv
- [ ] Analyze evaluation_consolidated.csv for scoring patterns
- [ ] Cross-reference conversation TSVs with query sets
- [ ] Profile Python scripts and their dependencies
- [ ] Generate summary statistics and visualizations
- [ ] Document findings and recommendations

## Planning
1. **Data Profiling**: Understand schema, row counts, null rates, data types
2. **Quality Check**: Identify missing data, encoding issues, duplicates
3. **Analysis**: Compare model performance metrics across queries
4. **Visualization**: Charts for win/loss/tie rates per model
5. **Documentation**: Final report with insights

## Considerations
- Data lives outside workspace at `C:\Users\perahmat\Downloads\scraping_raw_data_output\scraping_raw_data_output`
- TSV files may have encoding quirks ‚Äî check for BOM
- Python scripts may have external dependencies not installed locally
- Large files ‚Äî use streaming/chunked reads where possible

## ‚úÖ What Worked
- **Terminal `Get-ChildItem` for file discovery** ‚Äî fast recursive listing to understand folder structure before reading individual files.
- **Creating task with 7 subtasks upfront** ‚Äî gave clear structure and trackable progress from day one.

## ‚ùå What Didn't Work
- **`list_dir` tool on paths outside workspace** ‚Äî VS Code sandbox restricts it. Had to use terminal commands instead.
- **Assuming Python deps are installed** ‚Äî scripts have external imports that aren't available locally; need to profile requirements first.

## üß† AI Agent Notes
- Dataset is outside the workspace ‚Äî always use full absolute paths.
- TSV files may be large ‚Äî prefer streaming reads or `Select-Object -First N` for previews.
- This is an analysis task, not a coding task ‚Äî focus on data insights, not building software.
- User may want to compare model performance across different query categories.

## Status: üîÑ In Progress (14%)
